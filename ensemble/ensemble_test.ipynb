{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os \n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "base_result_path = \"/opt/ml/input/code/predictions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.96180.csv', '0.9577.csv', '0.9477.csv', '0.9537.csv', 'output.csv']\n"
     ]
    }
   ],
   "source": [
    "submission_files = os.listdir(base_result_path)\n",
    "print(submission_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['drp.en_ko.in_house.deepnatural_001892.jpg', 'drp.en_ko.in_house.deepnatural_002413.jpg', 'drp.en_ko.in_house.deepnatural_002415.jpg', 'drp.en_ko.in_house.deepnatural_002420.jpg', 'drp.en_ko.in_house.deepnatural_002436.jpg', 'drp.en_ko.in_house.deepnatural_002442.jpg', 'drp.en_ko.in_house.deepnatural_002458.jpg', 'drp.en_ko.in_house.deepnatural_002460.jpg', 'drp.en_ko.in_house.deepnatural_002492.jpg', 'drp.en_ko.in_house.deepnatural_002499.jpg', 'drp.en_ko.in_house.deepnatural_002517.jpg', 'drp.en_ko.in_house.deepnatural_002518.jpg', 'drp.en_ko.in_house.deepnatural_002523.jpg', 'drp.en_ko.in_house.deepnatural_002535.jpg', 'drp.en_ko.in_house.deepnatural_002538.jpg', 'drp.en_ko.in_house.deepnatural_002576.jpg', 'drp.en_ko.in_house.deepnatural_002578.jpg', 'drp.en_ko.in_house.deepnatural_002620.jpg', 'drp.en_ko.in_house.deepnatural_002623.jpg', 'drp.en_ko.in_house.deepnatural_002626.jpg', 'drp.en_ko.in_house.deepnatural_002631.jpg', 'drp.en_ko.in_house.deepnatural_002633.jpg', 'drp.en_ko.in_house.deepnatural_002671.jpg', 'drp.en_ko.in_house.deepnatural_002678.jpg', 'drp.en_ko.in_house.deepnatural_002679.jpg', 'drp.en_ko.in_house.deepnatural_002694.jpg', 'drp.en_ko.in_house.deepnatural_002712.jpg', 'drp.en_ko.in_house.deepnatural_002723.jpg', 'drp.en_ko.in_house.deepnatural_002752.jpg', 'drp.en_ko.in_house.deepnatural_002782.jpg', 'drp.en_ko.in_house.deepnatural_002793.jpg', 'drp.en_ko.in_house.deepnatural_002794.jpg', 'drp.en_ko.in_house.deepnatural_002795.jpg', 'drp.en_ko.in_house.deepnatural_002804.jpg', 'drp.en_ko.in_house.deepnatural_002824.jpg', 'drp.en_ko.in_house.deepnatural_002832.jpg', 'drp.en_ko.in_house.deepnatural_002838.jpg', 'drp.en_ko.in_house.deepnatural_002847.jpg', 'drp.en_ko.in_house.deepnatural_002875.jpg', 'drp.en_ko.in_house.deepnatural_002919.jpg', 'drp.en_ko.in_house.deepnatural_002928.jpg', 'drp.en_ko.in_house.deepnatural_002954.jpg', 'drp.en_ko.in_house.deepnatural_002955.jpg', 'drp.en_ko.in_house.deepnatural_003013.jpg', 'drp.en_ko.in_house.deepnatural_003016.jpg', 'drp.en_ko.in_house.deepnatural_003021.jpg', 'drp.en_ko.in_house.deepnatural_003031.jpg', 'drp.en_ko.in_house.deepnatural_003045.jpg', 'drp.en_ko.in_house.deepnatural_003046.jpg', 'drp.en_ko.in_house.deepnatural_003048.jpg', 'drp.en_ko.in_house.deepnatural_003050.jpg', 'drp.en_ko.in_house.deepnatural_003072.jpg', 'drp.en_ko.in_house.deepnatural_003101.jpg', 'drp.en_ko.in_house.deepnatural_003165.jpg', 'drp.en_ko.in_house.deepnatural_003200.jpg', 'drp.en_ko.in_house.deepnatural_003258.jpg', 'drp.en_ko.in_house.deepnatural_003260.jpg', 'drp.en_ko.in_house.deepnatural_003292.jpg', 'drp.en_ko.in_house.deepnatural_003293.jpg', 'drp.en_ko.in_house.deepnatural_003340.jpg', 'drp.en_ko.in_house.deepnatural_003362.jpg', 'drp.en_ko.in_house.deepnatural_003381.jpg', 'drp.en_ko.in_house.deepnatural_003385.jpg', 'drp.en_ko.in_house.deepnatural_003388.jpg', 'drp.en_ko.in_house.deepnatural_003389.jpg', 'drp.en_ko.in_house.deepnatural_003394.jpg', 'drp.en_ko.in_house.deepnatural_003400.jpg', 'drp.en_ko.in_house.deepnatural_003406.jpg', 'drp.en_ko.in_house.deepnatural_003411.jpg', 'drp.en_ko.in_house.deepnatural_003417.jpg', 'drp.en_ko.in_house.deepnatural_003441.jpg', 'drp.en_ko.in_house.deepnatural_003442.jpg', 'drp.en_ko.in_house.deepnatural_003445.jpg', 'drp.en_ko.in_house.deepnatural_003447.jpg', 'drp.en_ko.in_house.deepnatural_003448.jpg', 'drp.en_ko.in_house.deepnatural_003452.jpg', 'drp.en_ko.in_house.deepnatural_003479.jpg', 'drp.en_ko.in_house.deepnatural_003511.jpg', 'drp.en_ko.in_house.deepnatural_003528.jpg', 'drp.en_ko.in_house.deepnatural_003535.jpg', 'drp.en_ko.in_house.deepnatural_003542.jpg', 'drp.en_ko.in_house.deepnatural_003590.jpg', 'drp.en_ko.in_house.deepnatural_003610.jpg', 'drp.en_ko.in_house.deepnatural_003637.jpg', 'drp.en_ko.in_house.deepnatural_003644.jpg', 'drp.en_ko.in_house.deepnatural_003661.jpg', 'drp.en_ko.in_house.deepnatural_003700.jpg', 'drp.en_ko.in_house.deepnatural_003707.jpg', 'drp.en_ko.in_house.deepnatural_003749.jpg', 'drp.en_ko.in_house.deepnatural_003808.jpg', 'drp.en_ko.in_house.deepnatural_003810.jpg', 'drp.en_ko.in_house.deepnatural_003833.jpg', 'drp.en_ko.in_house.deepnatural_003871.jpg', 'drp.en_ko.in_house.deepnatural_003898.jpg', 'drp.en_ko.in_house.deepnatural_003910.jpg', 'drp.en_ko.in_house.deepnatural_003955.jpg', 'drp.en_ko.in_house.deepnatural_004002.jpg', 'drp.en_ko.in_house.deepnatural_004003.jpg', 'drp.en_ko.in_house.deepnatural_004004.jpg', 'drp.en_ko.in_house.deepnatural_004006.jpg'])\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "anno_list = defaultdict(list)\n",
    "\n",
    "for file in submission_files:\n",
    "    file_path = os.path.join(base_result_path,file)\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        anno = json.load(f)\n",
    "    file_list = sorted(anno['images'].keys())\n",
    "    for i in file_list:\n",
    "        bboxes = []\n",
    "        for word_info in anno['images'][i]['words'].values():\n",
    "            bboxes.append(np.array(word_info['points']))\n",
    "        anno_list[i].append(np.array(bboxes))\n",
    "\n",
    "print(anno_list.keys())\n",
    "print(len(anno_list['drp.en_ko.in_house.deepnatural_001892.jpg']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    # 각 박스의 좌표를 추출합니다.\n",
    "    xA1, yA1, xA3, yA3 = boxA[0][0], boxA[0][1], boxA[2][0], boxA[2][1]\n",
    "    xB1, yB1, xB3, yB3 = boxB[0][0], boxB[0][1], boxB[2][0], boxB[2][1]\n",
    "\n",
    "    # 겹치는 영역의 좌표를 계산합니다.\n",
    "    xA = max(xA1, xB1)\n",
    "    yA = max(yA1, yB1)\n",
    "    xB = min(xA3, xB3)\n",
    "    yB = min(yA3, yB3)\n",
    "\n",
    "    # 겹치는 영역의 넓이를 계산합니다.\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\n",
    "    # 두 박스의 넓이를 계산합니다.\n",
    "    boxAArea = (xA3 - xA1 + 1) * (yA3 - yA1 + 1)\n",
    "    boxBArea = (xB3 - xB1 + 1) * (yB3 - yB1 + 1)\n",
    "\n",
    "    # IoU를 계산합니다.\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    # IoU를 반환합니다.\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:45<00:00,  2.86s/it]\n"
     ]
    }
   ],
   "source": [
    "num_files = len(submission_files)\n",
    "ufo_result = dict(images=dict())\n",
    "\n",
    "for key in tqdm(anno_list.keys()):\n",
    "    # 한 이미지당 bbox\n",
    "    base = anno_list[key][0]\n",
    "    # print(f\"base shape: {np.array(base).shape}\")\n",
    "    for points in anno_list[key]:\n",
    "        if base.shape[0] < points.shape[0]:\n",
    "            base = points\n",
    "    new_points = []\n",
    "    \n",
    "    # 기본 box 순회 (4,2)\n",
    "    for base_point in base:\n",
    "        average_list = []\n",
    "        # 각 이미지당 bbox 순회 (n,4,2)\n",
    "        for points in anno_list[key]:\n",
    "            best_iou = 0\n",
    "            best_point = None\n",
    "            for point in points:\n",
    "                iou = bb_intersection_over_union(base_point,point)\n",
    "                if iou > 0.3 and iou > best_iou :\n",
    "                    best_iou = iou\n",
    "                    best_point = point\n",
    "                    \n",
    "            if best_point is not None:\n",
    "                average_list.append(best_point)\n",
    "        # average_list [n,4,2]\n",
    "        if len(average_list) > (num_files//2):\n",
    "            new_p = np.mean(np.array(average_list),axis=0)\n",
    "            new_points.append(new_p)\n",
    "            \n",
    "    # print(f\"new_point shape :{np.array(new_points).shape}\")\n",
    "    words_info = {idx: dict(points=bbox.tolist()) for idx, bbox in enumerate(new_points)}\n",
    "    ufo_result['images'][key] = dict(words=words_info)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fname = 'ensemble.csv'\n",
    "with open(os.path.join(\"/opt/ml/input/code/predictions/\", output_fname), 'w') as f:\n",
    "    json.dump(ufo_result, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
