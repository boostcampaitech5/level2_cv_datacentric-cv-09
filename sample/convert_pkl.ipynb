{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from east_dataset import EASTDataset\n",
    "from dataset import SceneTextDataset\n",
    "\n",
    "trainset = SceneTextDataset(\n",
    "        '/opt/ml/input/data/medical',\n",
    "        split='train',\n",
    "        image_size=2048,\n",
    "        crop_size=1024,\n",
    "        ignore_tags=['masked', 'excluded-region', 'maintable', 'stamp'],\n",
    "        normalize=False,\n",
    "        color_jitter=False\n",
    "    )\n",
    "trainset = EASTDataset(trainset, to_tensor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 16/500 [03:49<1:55:57, 14.37s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(trainset))):\n\u001b[0;32m----> 5\u001b[0m     g \u001b[39m=\u001b[39m trainset\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(i)\n\u001b[1;32m      6\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(file\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/opt/ml/input/data/pickle_data/train/\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.pkl\u001b[39m\u001b[39m'\u001b[39m,mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      7\u001b[0m         pickle\u001b[39m.\u001b[39mdump(g,f, protocol\u001b[39m=\u001b[39mpickle\u001b[39m.\u001b[39mHIGHEST_PROTOCOL)\n",
      "File \u001b[0;32m~/input/code/east_dataset.py:137\u001b[0m, in \u001b[0;36mEASTDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m    136\u001b[0m     \u001b[39m#start = time.time()\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     image, word_bboxes, roi_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx]\n\u001b[1;32m    138\u001b[0m     score_map, geo_map \u001b[39m=\u001b[39m generate_score_geo_maps(image, word_bboxes, map_scale\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmap_scale)\n\u001b[1;32m    140\u001b[0m     mask_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(image\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmap_scale), \u001b[39mint\u001b[39m(image\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmap_scale)\n",
      "File \u001b[0;32m~/input/code/dataset.py:415\u001b[0m, in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    407\u001b[0m vertices, labels \u001b[39m=\u001b[39m filter_vertices(\n\u001b[1;32m    408\u001b[0m     vertices,\n\u001b[1;32m    409\u001b[0m     labels,\n\u001b[1;32m    410\u001b[0m     ignore_under\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mignore_under_threshold,\n\u001b[1;32m    411\u001b[0m     drop_under\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop_under_threshold\n\u001b[1;32m    412\u001b[0m )\n\u001b[1;32m    414\u001b[0m image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(image_fpath)\n\u001b[0;32m--> 415\u001b[0m image, vertices \u001b[39m=\u001b[39m resize_img(image, vertices, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_size)\n\u001b[1;32m    416\u001b[0m image, vertices \u001b[39m=\u001b[39m adjust_height(image, vertices)\n\u001b[1;32m    417\u001b[0m image, vertices \u001b[39m=\u001b[39m rotate_img(image, vertices)\n",
      "File \u001b[0;32m~/input/code/dataset.py:241\u001b[0m, in \u001b[0;36mcrop_img\u001b[0;34m(img, vertices, labels, length)\u001b[0m\n\u001b[1;32m    239\u001b[0m cnt \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    240\u001b[0m \u001b[39mwhile\u001b[39;00m flag \u001b[39mand\u001b[39;00m cnt \u001b[39m<\u001b[39m \u001b[39m1000\u001b[39m:\n\u001b[0;32m--> 241\u001b[0m     cnt \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    242\u001b[0m     start_w \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrand() \u001b[39m*\u001b[39m remain_w)\n\u001b[1;32m    243\u001b[0m     start_h \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrand() \u001b[39m*\u001b[39m remain_h)\n",
      "File \u001b[0;32m~/input/code/dataset.py:200\u001b[0m, in \u001b[0;36mis_cross_text\u001b[0;34m(start_loc, length, vertices)\u001b[0m\n\u001b[1;32m    197\u001b[0m start_w, start_h \u001b[39m=\u001b[39m start_loc\n\u001b[1;32m    198\u001b[0m a \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([start_w, start_h, start_w \u001b[39m+\u001b[39m length, start_h, start_w \u001b[39m+\u001b[39m length, start_h \u001b[39m+\u001b[39m length,\n\u001b[1;32m    199\u001b[0m               start_w, start_h \u001b[39m+\u001b[39m length])\u001b[39m.\u001b[39mreshape((\u001b[39m4\u001b[39m, \u001b[39m2\u001b[39m))\n\u001b[0;32m--> 200\u001b[0m p1 \u001b[39m=\u001b[39m Polygon(a)\u001b[39m.\u001b[39mconvex_hull\n\u001b[1;32m    201\u001b[0m \u001b[39mfor\u001b[39;00m vertice \u001b[39min\u001b[39;00m vertices:\n\u001b[1;32m    202\u001b[0m     p2 \u001b[39m=\u001b[39m Polygon(vertice\u001b[39m.\u001b[39mreshape((\u001b[39m4\u001b[39m, \u001b[39m2\u001b[39m)))\u001b[39m.\u001b[39mconvex_hull\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/shapely/geometry/base.py:676\u001b[0m, in \u001b[0;36mBaseGeometry.intersection\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mintersection\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[1;32m    675\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns the intersection of the geometries\"\"\"\u001b[39;00m\n\u001b[0;32m--> 676\u001b[0m     \u001b[39mreturn\u001b[39;00m geom_factory(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimpl[\u001b[39m'\u001b[39;49m\u001b[39mintersection\u001b[39;49m\u001b[39m'\u001b[39;49m](\u001b[39mself\u001b[39;49m, other))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/shapely/topology.py:66\u001b[0m, in \u001b[0;36mBinaryTopologicalOp.__call__\u001b[0;34m(self, this, other, *args)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate(this)\n\u001b[1;32m     65\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate(other, stop_prepared\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 66\u001b[0m product \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(this\u001b[39m.\u001b[39;49m_geom, other\u001b[39m.\u001b[39;49m_geom, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     67\u001b[0m \u001b[39mif\u001b[39;00m product \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m     err \u001b[39m=\u001b[39m TopologicalError(\n\u001b[1;32m     69\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThis operation could not be performed. Reason: unknown\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  \n",
    "import pickle\n",
    "\n",
    "for i in tqdm(range(len(trainset))):\n",
    "    g = trainset.__getitem__(i)\n",
    "    with open(file=f'/opt/ml/input/data/pickle_data/train/{i}.pkl',mode='wb') as f:\n",
    "        pickle.dump(g,f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(valset))):\n",
    "    g = valset.__getitem__(i)\n",
    "    with open(file=f'/opt/ml/input/data/pickle_data/val/{i}.pkl',mode='wb') as f:\n",
    "        pickle.dump(g,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os \n",
    "import torch \n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, split):\n",
    "        self.datadir = data_dir\n",
    "        self.split = split \n",
    "        datalist = os.listdir(data_dir)\n",
    "        self.datalist = [d for d in datalist if d.endswith(\".pkl\")]\n",
    "        self.datalist.sort()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with open(file=f'/opt/ml/input/data/pickle_data/{self.split}/{idx}.pkl',mode='rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        image, score_map, geo_map, roi_mask = data\n",
    "        transform = A.Compose([A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),])\n",
    "\n",
    "        image = transform(image=image)['image']\n",
    "        image = torch.Tensor(image).permute(2, 0, 1)\n",
    "\n",
    "        score_map = torch.Tensor(score_map).permute(2, 0, 1)\n",
    "        geo_map = torch.Tensor(geo_map).permute(2, 0, 1)\n",
    "        roi_mask = torch.Tensor(roi_mask).permute(2, 0, 1)\n",
    "\n",
    "        return image, score_map, geo_map, roi_mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.datalist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Val Datset plk\n",
    "deteval 을 계산하는 val dataset 에서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import ValDataset\n",
    "\n",
    "val_dataset = ValDataset(root_dir=\"/opt/ml/input/data/medical\")\n",
    "\n",
    "input_img, word_bboxes, roi_mask, gt_score_map, gt_geo_map, ori_size, transcriptions = next(iter(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"input_img      {str(type(input_img)):<25s} {str(input_img.shape):<25s}\")\n",
    "print(f\"word_bboxes    {str(type(word_bboxes)):<25s} {str(word_bboxes.shape):<25s}\")\n",
    "print(f\"roi_mask       {str(type(roi_mask)):<25s} {str(roi_mask.shape):<25s}\")\n",
    "print(f\"gt_score_map   {str(type(gt_score_map)):<25s} {str(gt_score_map.shape):<25s}\")\n",
    "print(f\"gt_geo_map     {str(type(gt_geo_map)):<25s} {str(gt_geo_map.shape):<25s}\")\n",
    "print(f\"ori_size       {str(type(ori_size)):<25s} {str(ori_size):<25s}\")\n",
    "print(f\"transcriptions {str(type(transcriptions)):<25s} {str(len(transcriptions)):<25s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  \n",
    "import pickle\n",
    "\n",
    "for i in tqdm(range(len(val_dataset))):\n",
    "    g = val_dataset.__getitem__(i)\n",
    "    with open(file=f'/opt/ml/input/data/medical/pickle_data/val/{i}.pkl',mode='wb') as f:\n",
    "        pickle.dump(g,f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os \n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir = \"/opt/ml/input/data/medical/pickle_data/\", split='val'):\n",
    "        self.data_dir = data_dir\n",
    "        self.split = split \n",
    "        datalist = os.listdir(os.path.join(self.data_dir,self.split))\n",
    "        self.data_list = [d for d in datalist if d.endswith(\".pkl\")]\n",
    "        self.data_list.sort()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = os.path.join(self.data_dir,self.split,self.data_list[idx])\n",
    "        print(file_path)\n",
    "        with open(file=file_path,mode='rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        input_img, word_bboxes, roi_mask, gt_score_map, gt_geo_map, ori_size, transcriptions = data\n",
    "\n",
    "        return input_img, word_bboxes, roi_mask, gt_score_map, gt_geo_map, ori_size, transcriptions\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = CustomDataset()\n",
    "\n",
    "input_img, word_bboxes, roi_mask, gt_score_map, gt_geo_map, ori_size, transcriptions = next(iter(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"input_img      {str(type(input_img)):<25s} {str(input_img.shape):<25s}\")\n",
    "print(f\"word_bboxes    {str(type(word_bboxes)):<25s} {str(word_bboxes.shape):<25s}\")\n",
    "print(f\"roi_mask       {str(type(roi_mask)):<25s} {str(roi_mask.shape):<25s}\")\n",
    "print(f\"gt_score_map   {str(type(gt_score_map)):<25s} {str(gt_score_map.shape):<25s}\")\n",
    "print(f\"gt_geo_map     {str(type(gt_geo_map)):<25s} {str(gt_geo_map.shape):<25s}\")\n",
    "print(f\"ori_size       {str(type(ori_size)):<25s} {str(ori_size):<25s}\")\n",
    "print(f\"transcriptions {str(type(transcriptions)):<25s} {str(len(transcriptions)):<25s}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
